{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data to Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup our imports\n",
    "1. We'll be building pipelines to process our document, so we'll import Kodexa's Pipeline module\n",
    "2. Import all the FolderConnector - we'll provide it to the Pipeline in order to access our file\n",
    "3. Some of our parsing will need to happen in the could, so we'll import the KodexaPlatform and RemoteAction modules\n",
    "4. All files that have been processed/parsed in Kodexa become Kodexa Documents, so we'll import that module as well.\n",
    "\n",
    "We're also setting the CLOUD_URL value to the platform environment on which we want to perform our processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kodexa import *\n",
    "\n",
    "CLOUD_URL = 'https://platform.kodexa.com' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Platform Environment and Access Token Credential\n",
    "\n",
    "In the next cell, you'll be prompted to enter your access token that you've created in the environment specified by the CLOUD_URL.\n",
    "If you haven't created a token already, follow the steps in our [Getting Started](https://developer.kodexa.com/org-management/manage-access-token) guide.\n",
    "\n",
    "* Note:  The text you enter in the prompt field will be masked.  Once you're done entering the access token value, hit enter to complete the action in the cell.  **You will then need to manulally set control at the next cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# Only request a login if we aren't logged in\n",
    "\n",
    "if KodexaPlatform.get_access_token() is None:\n",
    "    ACCESS_TOKEN = getpass.getpass(\"Enter access token:\")\n",
    "\n",
    "    KodexaPlatform.set_url(CLOUD_URL)\n",
    "    KodexaPlatform.set_access_token(ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We'll be using one of the text files (parsed and saved as kdxa) to work through the examples - setting the path to it here\n",
    "import os\n",
    "\n",
    "# Setting up location of data folders and files\n",
    "DATA_FOLDER = '_data'\n",
    "TEXT_FOLDER = 'texts'\n",
    "TEXT_DATA_FILE = 'tongue_twister.kdxa'\n",
    "\n",
    "TEXT_FOLDER_PATH = os.path.join(os.getcwd(), '..', DATA_FOLDER, TEXT_FOLDER)\n",
    "FULL_PATH = os.path.join(TEXT_FOLDER_PATH, TEXT_DATA_FILE)\n",
    "\n",
    "# Getting our pre-processed document from the .*kdxa file\n",
    "kodexa_doc = Document.from_kdxa(FULL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's tag all the nodes that contain the word 'flue' AND write that data to a TableDataStore\n",
    "\n",
    "We're going to set up a pipeline and use the NodeTagger action to perform the tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a new pipeline.  We'll use the document we just loaded as the connector\n",
    "pipeline = Pipeline(kodexa_doc)\n",
    "\n",
    "# We only want those nodes of that contain the word 'flue'.  Tag any nodes that match with 'has_flue'\n",
    "pipeline.add_step(RemoteAction(slug='kodexa/node-tagger', \n",
    "                                     options={'selector':'//*[contentRegex(\".*flue.*\")]', 'tag_to_apply':'has_flue', 'node_only':True}))\n",
    "\n",
    "# Extract Tags to key/value pair\n",
    "pipeline.add_step(RemoteAction(slug='kodexa/tags-to-key-value-pair-extractor', options={\n",
    "    \"store_name\": \"tagged_data\",\n",
    "    \"include_node_content\": False\n",
    "}))\n",
    "\n",
    "pipeline.run()\n",
    "\n",
    "## Once again, getting the document off the pipeline\n",
    "tagged_kodexa_doc = pipeline.context.output_document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tagged_pairs_store = pipeline.context.get_store('tagged_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>tagged_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>has_flue</td>\n",
       "      <td>A flea and a fly got stuck in a flue.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>has_flue</td>\n",
       "      <td>So they flew through a flaw in the flue.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tag                            tagged_content\n",
       "0  has_flue     A flea and a fly got stuck in a flue.\n",
       "1  has_flue  So they flew through a flaw in the flue."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_pairs_store.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node uuid: 88781031-165e-44e0-9a67-b27cf1b646ea - contents: A flea and a fly got stuck in a flue.\n",
      "Feature: Feature [type='tag' name='has_flue' value='[{'start': None, 'end': None, 'value': None, 'data': None, 'uuid': '91a30633-0595-4601-b0aa-3a52f95813a4'}]' single='True']\n",
      "\n",
      "Node uuid: 3e297ffc-1adc-48bf-962f-13b272657cd5 - contents: Said the flea to the fly, \"What shall we do?\"\n",
      "\n",
      "Node uuid: efaae33d-aec9-4e7b-8b31-8d002194b7a8 - contents: Said the fly, \"Let us flee!\"\n",
      "\n",
      "Node uuid: a2254d7c-6abe-46c6-99ce-8171bf7b59b1 - contents: Said the flea, \"Let us fly!\"\n",
      "\n",
      "Node uuid: edb867e2-144c-475b-8da3-1c2ce35a13bc - contents: So they flew through a flaw in the flue.\n",
      "Feature: Feature [type='tag' name='has_flue' value='[{'start': None, 'end': None, 'value': None, 'data': None, 'uuid': '91a30633-0595-4601-b0aa-3a52f95813a4'}]' single='True']\n"
     ]
    }
   ],
   "source": [
    "for n in tagged_kodexa_doc.get_root().children:\n",
    "    print(f'\\nNode uuid: {n.uuid} - contents: {n.get_all_content()}')\n",
    "    for f in n.get_features():\n",
    "        print(f'Feature: {f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using custom functions as pipeline steps\n",
    "\n",
    "A pipeline step accepts a document and the pipeline's context and returns a document.  Using that signature, we can write custom functions as steps.\n",
    "\n",
    "We'll set up a \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TableDataStore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e86e68141e11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                      options={'selector':'//*[contentRegex(\".*flue.*\")]', 'tag_to_apply':'has_flue', 'node_only':True}))\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTableDataStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flue_node_uuid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TableDataStore' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a fuction that accepts both a document and a PipelineContext\n",
    "# IMPORTANT!  Your function must return the document.  All steps \n",
    "\n",
    "def extractor(document: Document, context: PipelineContext):\n",
    "    # An example of how we might extract into a value from the document into a dict\n",
    "    context.get_store('output').add(['test'])\n",
    "    return document\n",
    "\n",
    "\n",
    "\n",
    "# Getting our pre-processed document from the .*kdxa file (so it's clean without tags)\n",
    "kodexa_doc = Document.from_kdxa(FULL_PATH)\n",
    "\n",
    "pipeline = Pipeline(kodexa_doc)\n",
    "\n",
    "# We only want those nodes of that contain the word 'flue'.  Tag any nodes that match with 'has_flue'\n",
    "pipeline.add_step(RemoteAction(slug='kodexa/node-tagger', \n",
    "                                     options={'selector':'//*[contentRegex(\".*flue.*\")]', 'tag_to_apply':'has_flue', 'node_only':True}))\n",
    "\n",
    "pipeline.add_store('output', TableDataStore(columns=['flue_node_uuid']))\n",
    "\n",
    "\n",
    "\n",
    "pipeline.add_step(extractor)\n",
    "\n",
    "context = pipeline.run()\n",
    "\n",
    "assert pipeline.context.get_store('output').count() == 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kodexa_python_quickstart",
   "language": "python",
   "name": "kodexa_python_quickstart"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
