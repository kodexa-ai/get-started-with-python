{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Bank Statements - Bank of America Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example problem:  Bank statements come in every month and must be processed.  These statements may share a similar format but vary depending on customer, content, account types, etc.\n",
    "\n",
    "This notebook demonstrates how to extract several different categories of account data from a single statement.  \n",
    "\n",
    "We provide statements for two different months in order to demonstrate the flexibility provided in our tagging/extraction process.  The data differs slightly from month-to-month, some data is present in one month and not the next and some tables span more than one page on one month and not the next.  Our PatterTableTagger, used when extracting data from spatially analyzed documents such as PDFs, is flexible enough to handle these types of differences between documents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup our imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kodexa import Document, Pipeline, RemoteAction, KodexaPlatform\n",
    "\n",
    "CLOUD_URL = 'https://platform.kodexa.com' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Platform Environment and Access Token Credential\n",
    "\n",
    "In the next cell, you'll be prompted to enter your access token that you've created in the environment specified by the CLOUD_URL.\n",
    "If you haven't created a token already, follow the steps in our [Getting Started](https://developer.kodexa.com/kodexa-cloud/accessing-kodexa-cloud) guide.\n",
    "\n",
    "* Note:  The text you enter in the prompt field will be masked.  Once you're done entering the access token value, hit enter to complete the action in the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter access token: ································\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "ACCESS_TOKEN = getpass.getpass(\"Enter access token:\")\n",
    "\n",
    "KodexaPlatform.set_url(CLOUD_URL)\n",
    "KodexaPlatform.set_access_token(ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, parse the PDF\n",
    "\n",
    "We'll start by constructing a pipeline that parses the PDF.  We'll used this parsed Kodexa document for the rest of our processing.\n",
    "\n",
    "There are two sample documents provided in the _data folder - try parsing each of these documents and processing them to see how the data is extracted for each (parse & process one at a time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up a pipeline that parses the PDF.  We're doing this as a separate piece of work\n",
    "# so we can spend time really digging into the table tagging parameters later\n",
    "\n",
    "\n",
    "# May statement data\n",
    "pipeline = Pipeline.from_file('_data/BofA_2020_05_07.pdf')\n",
    "\n",
    "# June statement data\n",
    "#pipeline = Pipeline.from_file('_data/BofA_2020_06_09.pdf')\n",
    "pipeline.add_step(RemoteAction(slug='kodexa/pdf-parser', attach_source=True))\n",
    "pipeline.run()\n",
    "\n",
    "kodexa_doc = pipeline.context.output_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, we'll tag and extract the checking Account Summary table\n",
    "\n",
    "When tagging a table in a PDF document, we focus on the areas of the document above and below the table.  Tables may or may not have headers, may span multiple pages, and may have rows of varying heights.  We have parameters that can control for all of those variations in presentation.  Let's start with the basics!\n",
    "\n",
    "We'll be using the Pattern-based table tagger (slug 'kodexa/pattern-table-tagger') to identify tables in our PDF documents.  That tagger identifies and tags a table using text patterns and then leverages spatial awareness to find columns and rows.\n",
    "\n",
    "The pattern-table-tagger has three required parameters:\n",
    "* **tag_to_apply**:  The tag we'll apply to the table once it's identified.\n",
    "* **page_start_re**: A regular expression that identifies the page the table will be found on.  This could be a page number or any bit of text that appears on the page before the table contents begins.  If the table is the only data on the page, you can enter some text you expect to be in the table or an empty string.\n",
    "* **table_start_re**: A regular expression that identifies a line of text that starts the table, such as the the column header line or other identifier.\n",
    "\n",
    "In addition identifying the page_start and table_start, we're going to supply a few other parameters in order to extract specific table data:\n",
    "* **page_end_re**:  A regular expression that identifies the page the table will end on.  This could be the format of a page number or any bit of text that appears on the page after the table contents ends.\n",
    "* **table_end_re**:  A regular expression used to identify a line that is at the end of the table - important when the table spans multiple pages.\n",
    "* **include_end_line**:  Boolean indication we want to include the line identified by the table_end_re will in the tagged table data so it' available for extraction.\n",
    "\n",
    "\n",
    "We're also going to set the 'extract' parameter to True so we can access the tagged table as a TableDataStore.  That store can be directly converted to a pandas dataframe, which is a familiar data structure for most Python developers.\n",
    "\n",
    "* **extract**: Boolean value indicating that the tagged table should be added to the pipeline context's stores\n",
    "* extract_options - **store_name**: The name of the extracted table's TableDataStore\n",
    "* extract_options - **header_lines_count**: The number of lines we expect to be header data (default is 1).  Since our summary tables don't have named headers above the table data, we're setting that value to zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all existing tags from the document (if this cell has already been processed) so they don't interfere with our new round of tagging\n",
    "for t in kodexa_doc.get_root().get_all_tags():\n",
    "    [n.remove_tag(t) for n in kodexa_doc.select(\"//*[hasTag('\" + t + \"')]\")]\n",
    "    \n",
    "\n",
    "# Setting up the regex values for this table\n",
    "checking_account_summary_table_tag_name = \"Checking Account Summary\"\n",
    "checking_page_start_re = \"^Your.*Ch.*\"\n",
    "summary_table_start_re = \"^Beginning balance.*\"\n",
    "summary_table_end_re = \"^Ending balance.*$\"\n",
    "page_number_re = \".*Page \\d+ of \\d+$\"\n",
    "\n",
    "pipeline = Pipeline(kodexa_doc)\n",
    "pipeline.add_step(RemoteAction(slug='kodexa/pattern-table-tagger', \n",
    "                                     options={\"tag_to_apply\": checking_account_summary_table_tag_name, \n",
    "                                              \"page_start_re\": checking_page_start_re, \n",
    "                                              \"page_end_re\": page_number_re,\n",
    "                                              \"table_start_re\":summary_table_start_re, \n",
    "                                              \"table_end_re\": summary_table_end_re,\n",
    "                                              \"include_end_line\" : True,  #This is set so the summary Ending Balance line is also extracted\n",
    "                                              \"extract\":True, \n",
    "                                              \"extract_options\": {'store_name': checking_account_summary_table_tag_name, \n",
    "                                                                 'header_lines_count': 0}\n",
    "                                              }))\n",
    "\n",
    "\n",
    "context = pipeline.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 columns which have header values of: Index(['', ''], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beginning balance on April 10, 2020</td>\n",
       "      <td>$4,181.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deposits and other additions</td>\n",
       "      <td>14,118.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Withdrawals and other subtractions</td>\n",
       "      <td>-13,959.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Checks</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Service fees</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ending balance on May 7, 2020</td>\n",
       "      <td>$4,340.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  \n",
       "0  Beginning balance on April 10, 2020   $4,181.74\n",
       "1         Deposits and other additions   14,118.32\n",
       "2   Withdrawals and other subtractions  -13,959.83\n",
       "3                               Checks       -0.00\n",
       "4                         Service fees       -0.00\n",
       "5        Ending balance on May 7, 2020   $4,340.23"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if context.get_store(checking_account_summary_table_tag_name):\n",
    "    checking_summary_df = context.get_store(checking_account_summary_table_tag_name).to_df()\n",
    "    print(f'There are {len(checking_summary_df.columns)} columns which have header values of: {checking_summary_df.columns}')\n",
    "    display(checking_summary_df)\n",
    "else:\n",
    "    print(\"No checking summary extracted\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the extracted data\n",
    "\n",
    "We were able to identify and extract the data as expected (yea!).  Take a look at the column names - you'll see there aren't any.  We have two columns but both are identified with an empty string.  This table doesn't have a proper table header to reference, so there are no descriptive column names set for the dataframe.\n",
    "\n",
    "\n",
    "## Get the Savings summary\n",
    "\n",
    "We'll use a few of the same regex values that we defined for the checking summary extraction and add a few new ones that identify savings summary data.  If you look at the original PDF, you'll be able to see that the savings summary table is titled \"Account Summary\", same as the checking summary.  The savings summary table begins on a page with a heading of \"Your Regular Savings\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all existing tags from the document (if this cell has already been processed) so they don't interfere with our new round of tagging\n",
    "for t in kodexa_doc.get_root().get_all_tags():\n",
    "    [n.remove_tag(t) for n in kodexa_doc.select(\"//*[hasTag('\" + t + \"')]\")]\n",
    "\n",
    "    \n",
    "# Using the already processed PDF, so we can skip parsing\n",
    "pipeline = Pipeline(kodexa_doc)\n",
    "\n",
    "# Setting up the regex values for this table\n",
    "savings_account_summary_table_tag_name = \"Savings Account Summary\"\n",
    "savings_page_start_re = \"^Your.*Sa.*\"\n",
    "\n",
    "pipeline.add_step(RemoteAction(slug='kodexa/pattern-table-tagger', \n",
    "                                     options={\"tag_to_apply\": savings_account_summary_table_tag_name, \n",
    "                                              \"page_start_re\": savings_page_start_re, \n",
    "                                              \"page_end_re\": page_number_re,\n",
    "                                              \"table_start_re\":summary_table_start_re, \n",
    "                                              \"table_end_re\": summary_table_end_re,\n",
    "                                              \"include_end_line\" : True,  #This is set so the summary Ending Balance line is also extracted\n",
    "                                              \"extract\":True, \n",
    "                                              \"extract_options\": {'store_name': savings_account_summary_table_tag_name, \n",
    "                                                                  'header_lines_count': 0}\n",
    "                                              }))\n",
    "\n",
    "\n",
    "context = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 columns which have header values of: Index(['', ''], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beginning balance on April 10, 2020</td>\n",
       "      <td>$1,601.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deposits and other additions</td>\n",
       "      <td>275.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Withdrawals and other subtractions</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Service fees</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ending balance on May 7, 2020</td>\n",
       "      <td>$1,876.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 \n",
       "0  Beginning balance on April 10, 2020  $1,601.51\n",
       "1         Deposits and other additions     275.01\n",
       "2   Withdrawals and other subtractions      -0.00\n",
       "3                         Service fees      -0.00\n",
       "4        Ending balance on May 7, 2020  $1,876.52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if context.get_store(savings_account_summary_table_tag_name):\n",
    "    savings_summary_df = context.get_store(savings_account_summary_table_tag_name).to_df()\n",
    "    print(f'There are {len(savings_summary_df.columns)} columns which have header values of: {savings_summary_df.columns}')\n",
    "    display(savings_summary_df)\n",
    "else:\n",
    "    print(\"No savings summary extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the savings account summary output\n",
    "\n",
    "Again, we can see that our data was tagged and extracted as expected, and we can see that the columns in the dataframe have not been named.  This summary table doesn't have a proper table header either, so no descriptive names are set.\n",
    "\n",
    "## Get the detailed deposit and withdrawal information.\n",
    "\n",
    "Starting with checking, we'll get details for deposits and withdrawals.\n",
    "\n",
    "### New parameters for detailed transaction tables\n",
    "\n",
    "Take a look at the source PDF and you'll see that the detailed transaction sections (checking/savings deposits & withdrawals) all have a table header of \"Date\", \"Description\", and \"Amount\".  Our summary tables did not have header information, so we explicitly set the \"header_lines_count\" value to 0.  Since our detailed information has headers, we'll change that value to 1.\n",
    "\n",
    "Refer to the source PDF once again and you'll see that the data in the detailed transaction sections sometimes spans more than one line.  We can collapse that multi-line data into a single row by setting the \"col_index_with_text\" parameter to zero.\n",
    "\n",
    "* extract_options - **header_lines_count**: The number of lines we expect to be header data (default is 1).  We're explicitly setting the value to 1 for this example, but since 1 is the default, you could choose to omit this parameter all together.\n",
    "* extract_options - **col_index_with_text**: The index of the column where data we expect to see data.  We expect to see data in the 'Date' column, so we'll set the value as 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all existing tags from the document (if this cell has already been processed) so they don't interfere with our new round of tagging\n",
    "for t in kodexa_doc.get_root().get_all_tags():\n",
    "    [n.remove_tag(t) for n in kodexa_doc.select(\"//*[hasTag('\" + t + \"')]\")]\n",
    "\n",
    "    \n",
    "# Again, skip parsing by using the same doc we've already parsed\n",
    "pipeline = Pipeline(kodexa_doc)\n",
    "\n",
    "# Setting up the regex values for this table\n",
    "checking_deposits_table_tag_name = \"Checking Account Deposits\"\n",
    "detailed_transactions_header_re = '^Date\\s+Description\\s+Amount$'\n",
    "detailed_deposits_table_end = '^Total deposits.*'\n",
    "continued_re = '^continued.*$'\n",
    "\n",
    "deposit_re = '^Deposits.*additions$'\n",
    "\n",
    "pipeline.add_step(RemoteAction(slug='kodexa/pattern-table-tagger', \n",
    "                                     options={\"tag_to_apply\": checking_deposits_table_tag_name, \n",
    "                                              \"page_start_re\": deposit_re,  #since these are the checking deposits, we'll look for them in the checking section\n",
    "                                              \"page_end_re\": detailed_deposits_table_end, #this is text that appears at the end of the table - after it has spanned all pages\n",
    "                                              \"table_start_re\":detailed_transactions_header_re, \n",
    "                                              \"table_end_re\": continued_re,\n",
    "                                              \"extract\":True, \n",
    "                                              \"extract_options\": {'store_name': checking_deposits_table_tag_name, \n",
    "                                                                  'header_lines_count': 1,\n",
    "                                                                  'col_index_with_text': 0} #need the col_index_with_text to get all the entries on one line\n",
    "                                              }))\n",
    "\n",
    "\n",
    "context = pipeline.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 columns which have header values of: Index(['Date', 'Description', '', 'Amount'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Description</th>\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04/10/20</td>\n",
       "      <td>PLACE FOR JOBS DES:Payroll ID:CER000XX8XX2 IND...</td>\n",
       "      <td>CO</td>\n",
       "      <td>4,515.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04/15/20</td>\n",
       "      <td>ABC ENTERPRISES, L DES:PAYROLL ID:01X2000-XXX-...</td>\n",
       "      <td>CO</td>\n",
       "      <td>1,036.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/24/20</td>\n",
       "      <td>PLACE FOR JOBS DES:Payroll ID:CER000XX8XX2 IND...</td>\n",
       "      <td>CO</td>\n",
       "      <td>4,515.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/28/20</td>\n",
       "      <td>Transfer JANE SMITH</td>\n",
       "      <td></td>\n",
       "      <td>3,015.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04/30/20</td>\n",
       "      <td>ABC ENTERPRISES, L DES:PAYROLL ID:01X2000-XXX-...</td>\n",
       "      <td>CO</td>\n",
       "      <td>1,036.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                        Description        Amount\n",
       "0  04/10/20  PLACE FOR JOBS DES:Payroll ID:CER000XX8XX2 IND...  CO  4,515.02\n",
       "1  04/15/20  ABC ENTERPRISES, L DES:PAYROLL ID:01X2000-XXX-...  CO  1,036.14\n",
       "2  04/24/20  PLACE FOR JOBS DES:Payroll ID:CER000XX8XX2 IND...  CO  4,515.03\n",
       "3  04/28/20                                Transfer JANE SMITH      3,015.91\n",
       "4  04/30/20  ABC ENTERPRISES, L DES:PAYROLL ID:01X2000-XXX-...  CO  1,036.22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if context.get_store(checking_deposits_table_tag_name):\n",
    "    checking_deposit_df = context.get_store(checking_deposits_table_tag_name).to_df()\n",
    "    print(f'There are {len(checking_deposit_df.columns)} columns which have header values of: {checking_deposit_df.columns}')\n",
    "    display(checking_deposit_df)\n",
    "else:\n",
    "    print(\"No checking deposit detail information extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Examine the checking deposit summary output\n",
    "\n",
    "It looks like our table was tagged and our data was extracted, but we've got 4 columns instead of the expected 3.  The alignment of the text \"CO\", spaced far off the rest of the description text, makes it look like that data could be in its own column.  We know that the data really belongs to the \"Description\" column, so we're going to provide a new parameter so the data is merged correctly.\n",
    "\n",
    "* extract_options - **col_marker_re**:  A regular expression that identifies a row in the table that can indicate specific positions of the columns.  In this case, we have a header row that indicates column positions.  If we didn't have a header row, we could use some other row in the table to serve as the 'master' position indicators.  Note - this option is not always necessary, but is useful when data is randomly spaced within a column.\n",
    "\n",
    "\n",
    "## Set the new col_marker_re option and execute the extraction again\n",
    "\n",
    "Once again, extracting detailed checking deposit information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all existing tags from the document (if this cell has already been processed) so they don't interfere with our new round of tagging\n",
    "for t in kodexa_doc.get_root().get_all_tags():\n",
    "    [n.remove_tag(t) for n in kodexa_doc.select(\"//*[hasTag('\" + t + \"')]\")]\n",
    "\n",
    "    \n",
    "# Using the same doc we've already parsed\n",
    "pipeline = Pipeline(kodexa_doc)\n",
    "pipeline.add_step(RemoteAction(slug='kodexa/pattern-table-tagger', \n",
    "                                     options={\"tag_to_apply\": checking_deposits_table_tag_name, \n",
    "                                              \"page_start_re\": deposit_re,  #since these are the checking deposits, we'll look for them in the checking section\n",
    "                                              \"page_end_re\": detailed_deposits_table_end, #this is text that appears at the end of the table - after it has spanned all pages\n",
    "                                              \"table_start_re\":detailed_transactions_header_re, \n",
    "                                              \"table_end_re\": continued_re,\n",
    "                                              \"col_marker_re\" : detailed_transactions_header_re,\n",
    "                                              \"extract\":True, \n",
    "                                              \"extract_options\": {'store_name': checking_deposits_table_tag_name, \n",
    "                                                                  'header_lines_count': 1,\n",
    "                                                                  'col_index_with_text': 0} #need the col_index_with_text to get all the entries on one line\n",
    "                                              }))\n",
    "\n",
    "\n",
    "context = pipeline.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 columns which have header values of: Index(['Date', 'Description', 'Amount'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Description</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04/10/20</td>\n",
       "      <td>PLACE FOR JOBS DES:Payroll ID:CER000XX8XX2 IND...</td>\n",
       "      <td>4,515.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04/15/20</td>\n",
       "      <td>ABC ENTERPRISES, L DES:PAYROLL ID:01X2000-XXX-...</td>\n",
       "      <td>1,036.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/24/20</td>\n",
       "      <td>PLACE FOR JOBS DES:Payroll ID:CER000XX8XX2 IND...</td>\n",
       "      <td>4,515.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/28/20</td>\n",
       "      <td>Transfer JANE SMITH</td>\n",
       "      <td>3,015.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04/30/20</td>\n",
       "      <td>ABC ENTERPRISES, L DES:PAYROLL ID:01X2000-XXX-...</td>\n",
       "      <td>1,036.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                        Description    Amount\n",
       "0  04/10/20  PLACE FOR JOBS DES:Payroll ID:CER000XX8XX2 IND...  4,515.02\n",
       "1  04/15/20  ABC ENTERPRISES, L DES:PAYROLL ID:01X2000-XXX-...  1,036.14\n",
       "2  04/24/20  PLACE FOR JOBS DES:Payroll ID:CER000XX8XX2 IND...  4,515.03\n",
       "3  04/28/20                                Transfer JANE SMITH  3,015.91\n",
       "4  04/30/20  ABC ENTERPRISES, L DES:PAYROLL ID:01X2000-XXX-...  1,036.22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if context.get_store(checking_deposits_table_tag_name):\n",
    "    checking_deposit_df = context.get_store(checking_deposits_table_tag_name).to_df()\n",
    "    print(f'There are {len(checking_deposit_df.columns)} columns which have header values of: {checking_deposit_df.columns}')\n",
    "    display(checking_deposit_df)\n",
    "else:\n",
    "    print(\"No checking deposit detail information extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fantastic!  Now we have the expected number of columns!\n",
    "\n",
    "Since the format of the checking withdrawal table is the same as that used for the checking deposit table, we'll use that \"col_marker_re\" parameter for the next table data extraction as well.\n",
    "\n",
    "### Checking withdrawals\n",
    "\n",
    "Again, we'll use the same approach (and several of the same regex values) for this table as we did for the deposits table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all existing tags from the document (if this cell has already been processed) so they don't interfere with our new round of tagging\n",
    "for t in kodexa_doc.get_root().get_all_tags():\n",
    "    [n.remove_tag(t) for n in kodexa_doc.select(\"//*[hasTag('\" + t + \"')]\")]\n",
    "\n",
    "\n",
    "# Using the previously parsed kodexa_doc\n",
    "pipeline = Pipeline(kodexa_doc)\n",
    "\n",
    "# Setting up the regex values for this table\n",
    "checking_withdrawals_page_start_re = \"^W.*als.*subtractions$\"  #\n",
    "checking_withdrawals_table_tag_name = \"Checking Account Withdrawals\"\n",
    "detailed_withdrawal_table_end = '^Total withd.*'\n",
    "\n",
    "pipeline.add_step(RemoteAction(slug='kodexa/pattern-table-tagger', \n",
    "                                     options={\"tag_to_apply\": checking_withdrawals_table_tag_name, \n",
    "                                              \"page_start_re\": checking_withdrawals_page_start_re,  #since these are the checking deposits, we'll look for them in the checking section\n",
    "                                              \"page_end_re\": detailed_withdrawal_table_end, #this is text that appears at the end of the table - after it has spanned all pages\n",
    "                                              \"table_start_re\":detailed_transactions_header_re, \n",
    "                                              \"table_end_re\": continued_re,\n",
    "                                              \"col_marker_re\" : detailed_transactions_header_re,\n",
    "                                              \"extract\":True, \n",
    "                                              \"extract_options\": {'store_name': checking_withdrawals_table_tag_name, \n",
    "                                                                  'header_lines_count': 1,\n",
    "                                                                  'col_index_with_text': 0} #need the col_index_with_text to get all the entries on one line\n",
    "                                              }))\n",
    "\n",
    "\n",
    "context = pipeline.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 columns which have header values of: Index(['Date', 'Description', 'Amount'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Description</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04/10/20</td>\n",
       "      <td>CAPITAL ONE DES:ONLINE PMT ID:0101399XXXX656 I...</td>\n",
       "      <td>-50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04/13/20</td>\n",
       "      <td>Low e s C C DES:LWS EPAY ID:233XXXX2 INDN: 79X...</td>\n",
       "      <td>-74.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/14/20</td>\n",
       "      <td>BANK DES:$TRANSFER ID:2XXXXXXX1 INDN:JANE SMIT...</td>\n",
       "      <td>-300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/14/20</td>\n",
       "      <td>LIFE DES:INSUR PREM ID:P 2AXXXXX756 INDN:SMITH...</td>\n",
       "      <td>-61.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04/15/20</td>\n",
       "      <td>AMERICAN EXPRESS DES:ACH PMT ID:WXXX2 INDN:JAN...</td>\n",
       "      <td>-194.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>04/16/20</td>\n",
       "      <td>BKOFAMERICA ATM 04/16 #000XXXXX2 WITHDRWL CHAR...</td>\n",
       "      <td>-300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>04/16/20</td>\n",
       "      <td>BANK DES:$TRANSFER ID:2XXXXXXX1 INDN:JANE SMIT...</td>\n",
       "      <td>-75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>04/17/20</td>\n",
       "      <td>WATER DES:UTIL-PMNT ID:22XXXX1 INDN:SMITH JOE ...</td>\n",
       "      <td>-37.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>04/20/20</td>\n",
       "      <td>BKOFAMERICA ATM 04/18 #000XXXXX2 WITHDRWL CHAR...</td>\n",
       "      <td>-40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>04/20/20</td>\n",
       "      <td>CHECKCARD 0419 PAYPAL *EBAYINCSHIP 402-935-773...</td>\n",
       "      <td>-8.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>04/20/20</td>\n",
       "      <td>RENEWWEB DES:7XX5XX33X ID:02XXXX INDN:JANE SMI...</td>\n",
       "      <td>-50.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>04/21/20</td>\n",
       "      <td>BKOFAMERICA ATM 04/21 #000XXXXX2 WITHDRWL CHAR...</td>\n",
       "      <td>-100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>04/22/20</td>\n",
       "      <td>Bill Payment</td>\n",
       "      <td>-30.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>04/22/20</td>\n",
       "      <td>Bill Payment</td>\n",
       "      <td>-15.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>04/24/20</td>\n",
       "      <td>Bank DES:CC PYMT ID:60XXXX210XXXX22 INDN:SMITH...</td>\n",
       "      <td>-165.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>04/27/20</td>\n",
       "      <td>INS GROUP DES:EXPSPAY ID:QXXXXXXXXX INDN:JANE ...</td>\n",
       "      <td>-91.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>04/28/20</td>\n",
       "      <td>CHECKCARD 0500 PAYPAL *EBAYINCSHIP 402-900-000...</td>\n",
       "      <td>-8.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>04/28/20</td>\n",
       "      <td>CARD SRVC DES:BILL PAY ID:000000004XXXX4 INDN:...</td>\n",
       "      <td>-62.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>04/29/20</td>\n",
       "      <td>BANK DES:$TRANSFER ID:22XXXXX7 INDN:JANE SMITH...</td>\n",
       "      <td>-750.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>04/29/20</td>\n",
       "      <td>BANK DES:$TRANSFER ID:22XXXXX5 INDN:JANE SMITH...</td>\n",
       "      <td>-300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>04/29/20</td>\n",
       "      <td>BANK DES:$TRANSFER ID:22XXXXX5 INDN:JANE SMITH...</td>\n",
       "      <td>-100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>04/29/20</td>\n",
       "      <td>Low e s C C DES:LWS EPAY ID:3XXXXXX7 INDN: 79X...</td>\n",
       "      <td>-6.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>05/01/20</td>\n",
       "      <td>Transfer Conf# 6XXUXXX0; Smith, Joey</td>\n",
       "      <td>-163.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>05/01/20</td>\n",
       "      <td>Bill Payment</td>\n",
       "      <td>-7,213.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>05/01/20</td>\n",
       "      <td>Bill Payment</td>\n",
       "      <td>-2,733.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>05/01/20</td>\n",
       "      <td>Transfer Confirmation# 1XXXXXXX8</td>\n",
       "      <td>-275.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>05/01/20</td>\n",
       "      <td>AMERICAN EXPRESS DES:ACH PMT ID:W7370 INDN:SMI...</td>\n",
       "      <td>-270.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>05/07/20</td>\n",
       "      <td>Car Payment DES:BANK OF AM ID:SMITH, JANE ID:9...</td>\n",
       "      <td>-480.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                        Description     Amount\n",
       "0   04/10/20  CAPITAL ONE DES:ONLINE PMT ID:0101399XXXX656 I...     -50.00\n",
       "1   04/13/20  Low e s C C DES:LWS EPAY ID:233XXXX2 INDN: 79X...     -74.89\n",
       "2   04/14/20  BANK DES:$TRANSFER ID:2XXXXXXX1 INDN:JANE SMIT...    -300.00\n",
       "3   04/14/20  LIFE DES:INSUR PREM ID:P 2AXXXXX756 INDN:SMITH...     -61.63\n",
       "4   04/15/20  AMERICAN EXPRESS DES:ACH PMT ID:WXXX2 INDN:JAN...    -194.94\n",
       "5   04/16/20  BKOFAMERICA ATM 04/16 #000XXXXX2 WITHDRWL CHAR...    -300.00\n",
       "6   04/16/20  BANK DES:$TRANSFER ID:2XXXXXXX1 INDN:JANE SMIT...     -75.00\n",
       "7   04/17/20  WATER DES:UTIL-PMNT ID:22XXXX1 INDN:SMITH JOE ...     -37.82\n",
       "8   04/20/20  BKOFAMERICA ATM 04/18 #000XXXXX2 WITHDRWL CHAR...     -40.00\n",
       "9   04/20/20  CHECKCARD 0419 PAYPAL *EBAYINCSHIP 402-935-773...      -8.76\n",
       "10  04/20/20  RENEWWEB DES:7XX5XX33X ID:02XXXX INDN:JANE SMI...     -50.47\n",
       "11  04/21/20  BKOFAMERICA ATM 04/21 #000XXXXX2 WITHDRWL CHAR...    -100.00\n",
       "12  04/22/20                                       Bill Payment     -30.76\n",
       "13  04/22/20                                       Bill Payment     -15.91\n",
       "14  04/24/20  Bank DES:CC PYMT ID:60XXXX210XXXX22 INDN:SMITH...    -165.00\n",
       "15  04/27/20  INS GROUP DES:EXPSPAY ID:QXXXXXXXXX INDN:JANE ...     -91.75\n",
       "16  04/28/20  CHECKCARD 0500 PAYPAL *EBAYINCSHIP 402-900-000...      -8.12\n",
       "17  04/28/20  CARD SRVC DES:BILL PAY ID:000000004XXXX4 INDN:...     -62.72\n",
       "18  04/29/20  BANK DES:$TRANSFER ID:22XXXXX7 INDN:JANE SMITH...    -750.00\n",
       "19  04/29/20  BANK DES:$TRANSFER ID:22XXXXX5 INDN:JANE SMITH...    -300.00\n",
       "20  04/29/20  BANK DES:$TRANSFER ID:22XXXXX5 INDN:JANE SMITH...    -100.00\n",
       "21  04/29/20  Low e s C C DES:LWS EPAY ID:3XXXXXX7 INDN: 79X...      -6.53\n",
       "22  05/01/20               Transfer Conf# 6XXUXXX0; Smith, Joey    -163.52\n",
       "23  05/01/20                                       Bill Payment  -7,213.34\n",
       "24  05/01/20                                       Bill Payment  -2,733.67\n",
       "25  05/01/20                   Transfer Confirmation# 1XXXXXXX8    -275.00\n",
       "26  05/01/20  AMERICAN EXPRESS DES:ACH PMT ID:W7370 INDN:SMI...    -270.00\n",
       "27  05/07/20  Car Payment DES:BANK OF AM ID:SMITH, JANE ID:9...    -480.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if context.get_store(checking_withdrawals_table_tag_name):\n",
    "    checking_withdrawals_df = context.get_store(checking_withdrawals_table_tag_name).to_df()\n",
    "    print(f'There are {len(checking_withdrawals_df.columns)} columns which have header values of: {checking_withdrawals_df.columns}')\n",
    "    display(checking_withdrawals_df)\n",
    "else:\n",
    "    print(\"No checking withdrawal detail information extracted\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now detailed Savings information\n",
    "\n",
    "### Savings Deposits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all existing tags from the document (if this cell has already been processed) so they don't interfere with our new round of tagging\n",
    "for t in kodexa_doc.get_root().get_all_tags():\n",
    "    [n.remove_tag(t) for n in kodexa_doc.select(\"//*[hasTag('\" + t + \"')]\")]\n",
    "\n",
    "\n",
    "pipeline = Pipeline(kodexa_doc)\n",
    "\n",
    "# Setting up the regex values for this table\n",
    "savings_deposit_page_start_re = \"^Your.*Sav.*\"\n",
    "savings_deposits_table_tag_name = \"Savings Account Deposits\"\n",
    "\n",
    "pipeline.add_step(RemoteAction(slug='kodexa/pattern-table-tagger', \n",
    "                                     options={\"tag_to_apply\": savings_deposits_table_tag_name, \n",
    "                                              \"page_start_re\": savings_deposit_page_start_re,  #since these are the checking deposits, we'll look for them in the checking section\n",
    "                                              \"page_end_re\": detailed_deposits_table_end, #this is text that appears at the end of the table - after it has spanned all page\n",
    "                                              \"table_start_re\":detailed_transactions_header_re, \n",
    "                                              \"table_end_re\": continued_re,\n",
    "                                              \"extract\":True, \n",
    "                                              \"extract_options\": {'store_name': savings_deposits_table_tag_name, \n",
    "                                                                  'header_lines_count': 1,\n",
    "                                                                  'col_index_with_text': 0} #need the col_index_with_text to get all the entries on one line\n",
    "                                              }))\n",
    "\n",
    "\n",
    "context = pipeline.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 columns which have header values of: Index(['Date', 'Description', 'Amount'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Description</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05/01/20</td>\n",
       "      <td>Automatic Transfer from CHK 0000 Confirmation#...</td>\n",
       "      <td>275.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/07/20</td>\n",
       "      <td>Interest Earned</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                        Description  Amount\n",
       "0  05/01/20  Automatic Transfer from CHK 0000 Confirmation#...  275.00\n",
       "1  05/07/20                                    Interest Earned    0.01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if context.get_store(savings_deposits_table_tag_name):\n",
    "    savings_deposits_df = context.get_store(savings_deposits_table_tag_name).to_df()\n",
    "    print(f'There are {len(savings_deposits_df.columns)} columns which have header values of: {savings_deposits_df.columns}')\n",
    "    display(savings_deposits_df)\n",
    "else:\n",
    "    print('No savings deposit detail information extracted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Savings Withdrawals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all existing tags from the document (if this cell has already been processed) so they don't interfere with our new round of tagging\n",
    "for t in kodexa_doc.get_root().get_all_tags():\n",
    "    [n.remove_tag(t) for n in kodexa_doc.select(\"//*[hasTag('\" + t + \"')]\")]\n",
    "\n",
    "\n",
    "pipeline = Pipeline(kodexa_doc)\n",
    "\n",
    "# Setting up the regex values for this table\n",
    "savings_withdrawals_page_start_re = \"^Your.*Sav.*$\"\n",
    "savings_withdrawals_table_tag_name = \"Savings Account Withdrawals\"\n",
    "\n",
    "pipeline.add_step(RemoteAction(slug='kodexa/pattern-table-tagger', \n",
    "                                     options={\"tag_to_apply\": savings_withdrawals_table_tag_name, \n",
    "                                              \"page_start_re\": savings_withdrawals_page_start_re,  #since these are the checking deposits, we'll look for them in the checking section\n",
    "                                              \"page_end_re\": detailed_withdrawal_table_end, #this is text that appears at the end of the table - after it has spanned all page\n",
    "                                              \"table_start_re\":'^Withdrawals and other subtractions$', \n",
    "                                              \"table_end_re\": continued_re,\n",
    "                                              \"extract\":True, \n",
    "                                              \"extract_options\": {'store_name': savings_withdrawals_table_tag_name, \n",
    "                                                                  'header_lines_count': 1,\n",
    "                                                                  'col_index_with_text': 0} #need the col_index_with_text to get all the entries on one line\n",
    "                                              }))\n",
    "\n",
    "\n",
    "context = pipeline.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No savings withdrawal detail information extracted\n"
     ]
    }
   ],
   "source": [
    "if context.get_store(savings_withdrawals_table_tag_name):\n",
    "    savings_withdrawals_df = context.get_store(savings_withdrawals_table_tag_name).to_df()\n",
    "    print(f'There are {len(savings_withdrawals_df.columns)} columns which have header values of: {savings_withdrawals_df.columns}')\n",
    "    display(savings_withdrawals_df)\n",
    "    \n",
    "else:\n",
    "    print('No savings withdrawal detail information extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bank_statements",
   "language": "python",
   "name": "bank_statements"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
